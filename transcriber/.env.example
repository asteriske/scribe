# Transcriber Service Configuration
# Copy this file to .env and update with your settings

# ===== Service Configuration =====
HOST=0.0.0.0
PORT=8001
WORKERS=1
LOG_LEVEL=INFO

# ===== Model Configuration =====
# Options: tiny, base, small, medium, large-v3
WHISPER_MODEL=medium

# Where to cache model files
MODEL_DIR=~/.cache/whisper

# ===== Job Queue Configuration =====
# Maximum number of concurrent transcription jobs (recommend 1 for MLX)
MAX_CONCURRENT_JOBS=1

# Maximum number of jobs in queue
QUEUE_SIZE=10

# How long to keep completed job results in memory (hours)
JOB_RETENTION_HOURS=1

# ===== Performance Configuration =====
# Compute type: float16 (faster, recommended) or float32
COMPUTE_TYPE=float16

# ===== Logging Configuration =====
# Log file path (relative to project root)
LOG_FILE=data/logs/transcriber.log

# Log format: json or text
LOG_FORMAT=text
